{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dffedfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ImageDataAugmentor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpre_train\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_parameter\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
      "File \u001b[1;32m~\\Desktop\\Skin Cancer Detections\\Skin-Cancer-Classification-using-Deep-Learning\\Src\\Model Training\\pre_train.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mImageDataAugmentor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_data_augmentor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataAugmentor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialise the EfficientNet Model for transfer learning\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ImageDataAugmentor'"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "from glob import glob\n",
    "from functools import reduce\n",
    "import os \n",
    "import sys\n",
    "import yaml\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "import utils\n",
    "import pre_train\n",
    "from model_param import model_parameter\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "from ImageDataAugmentor.image_data_augmentor import ImageDataAugmentor\n",
    "\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core.compute import ComputeTarget, ComputeInstance\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load Azure subscription Detail\n",
    "    # Subscription detail for Instance one\n",
    "    azure_auth_stream = open(\"Azure_outh_settings_INSTANCE_1.yml\", 'r')\n",
    "    # Subscription detail for Instance two\n",
    "    #azure_auth_stream = open(\"Azure_outh_settings_INSTANCE_2.yml\", 'r')\n",
    "\n",
    "    azure_settings = yaml.load(azure_auth_stream, yaml.SafeLoader)\n",
    "\n",
    "    ## Change working Directory \n",
    "    os.chdir('../')\n",
    "    print(\"\\nCurrent Working Directory: \", os.getcwd())\n",
    "\n",
    "    # Azure subscription detail\n",
    "    subscription_id = azure_settings['subscription_id']\n",
    "    resource_group = azure_settings['resource_group']\n",
    "    workspace_name = azure_settings['workspace_name']\n",
    "\n",
    "    workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "    print(\"\\nAzure Workspace Name: \", workspace.name)\n",
    "    print(\"Azure Workspace Resource Group: \", workspace.resource_group)\n",
    "\n",
    "    # Initialise Azure Instance\n",
    "    try:\n",
    "        instance = ComputeInstance(workspace = workspace, name = azure_settings['instance_name'])\n",
    "        # Get Status\n",
    "        print('Azure ML Instance is {}.\\n'.format(instance.get_status().state))       \n",
    "    except:\n",
    "        print(\"An exception occurred while initialising the Azure ML Compute\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Select model to train\n",
    "    # We have model2, model10, model16 and model12 model available\n",
    "    model_config = 'model10'\n",
    "\n",
    "    # Get the model parameters\n",
    "    selected_model = model_parameter(model_config)\n",
    "\n",
    "    # Define Model Log and Plot files\n",
    "    log_path = \"./runs/\"\n",
    "    os.makedirs(log_path, exist_ok = True)\n",
    "\n",
    "    plot_path = \"./plot/\"\n",
    "    os.makedirs(plot_path, exist_ok = True)\n",
    "\n",
    "    ##################### Define path for Training and Testing Data\n",
    "    train_path = \"./{0}x{0}/\".format(selected_model['input_image_size'])\n",
    "    test_path = \"./{0}x{0}_test/\".format(selected_model['input_image_size'])\n",
    "\n",
    "    save_model_path = \"./saveModel/\"\n",
    "    os.makedirs(save_model_path, exist_ok = True)\n",
    "    \n",
    "    ##################### Get Training and Testing Labels from Azure Instance\n",
    "    train_label = Dataset.get_by_name(workspace, name='train_2020_and_2019_with_9_Labels')\n",
    "    test_label = Dataset.get_by_name(workspace, name='test_2020_no_PateintDetail')\n",
    "\n",
    "    label = train_label.to_pandas_dataframe()\n",
    "    test_csv = test_label.to_pandas_dataframe()\n",
    "\n",
    "    # Append Image extension and file path to train and test CSV\n",
    "    absolute_path_train = os.path.abspath(train_path)\n",
    "    label = utils.append_path(label, absolute_path_train)\n",
    "\n",
    "    absolute_path_test = os.path.abspath(test_path)\n",
    "    test_csv = utils.append_path(test_csv, absolute_path_test)\n",
    "\n",
    "    ##################### Hyper Parameter\n",
    "    hyper_param = {\n",
    "        'seed': 42,\n",
    "        'image_size': selected_model['resize'], # resize image \n",
    "        'backbone_model': selected_model['backbone'], # Pretrained model name\n",
    "        'early_stop': 10,\n",
    "        'num_class': selected_model['target'],\n",
    "        'train_batch_size': selected_model['train_batch_size'], # Train Batch Size\n",
    "        'test_batch_size': 1, # Testing set batch size\n",
    "        'validation_batch_size': selected_model['validation_batch_size'], # Validation Batch Size\n",
    "        'epoch': selected_model['epochs'],\n",
    "        'warmup_epoch': 1,\n",
    "        'learning_rate_base': selected_model['initial_lr'], # Base learning rate after warmup.\n",
    "        'warmup_learning_rate': selected_model['initial_lr'], # Warmup learning rate\n",
    "        'training_sample_count': label.shape[0], # Number of training sample\n",
    "        'save_model': selected_model['savedModelByName'], # save model name\n",
    "        'save_final_model': selected_model['saveFinalModelBy'] # Save final trained model in Tensorflow Format\n",
    "    }  \n",
    "\n",
    "    image_resize = (hyper_param['image_size'], hyper_param['image_size'])\n",
    "    image_shape = image_resize + (3, )\n",
    "    # Total training steps in Warmup\n",
    "    total_steps = int(hyper_param['epoch'] * hyper_param['training_sample_count'] / hyper_param['train_batch_size'])\n",
    "    # Compute the number of warmup batches.\n",
    "    warmup_steps = int(hyper_param['warmup_epoch'] * hyper_param['training_sample_count'] / hyper_param['train_batch_size'])\n",
    "\n",
    "    # Print Hyper parameter\n",
    "    if selected_model['print_hyper_parameter']:\n",
    "        print(\"\\n####################### Hyper Parameter #################################\\n\")\n",
    "        pprint.pprint(hyper_param)\n",
    "        \n",
    "        print('\\nImage Shape: {}'.format(image_shape))\n",
    "        print('Total training steps in Warmup: {}'.format(total_steps))\n",
    "        print('Number of Warmup Batch: {}\\n'.format(warmup_steps))\n",
    "        print(\"\\nTrain Label shape: \", label.shape) \n",
    "        print(\"Test Label shape: \", test_csv.shape) \n",
    "\n",
    "    ########################### Train model\n",
    "    # Create the Learning rate scheduler.\n",
    "    warm_up_lr = utils.WarmUpCosineDecayScheduler(learning_rate_base = hyper_param['learning_rate_base'],\n",
    "                                            total_steps = total_steps,\n",
    "                                            warmup_learning_rate = hyper_param['warmup_learning_rate'],\n",
    "                                            warmup_steps = warmup_steps,\n",
    "                                            hold_base_rate_steps = 0)\n",
    "\n",
    "    # Initialise Pre-train Model\n",
    "    model = pre_train.EffNet(input_size = image_shape, num_classess = hyper_param['num_class'], \\\n",
    "        pretrained_model = hyper_param['backbone_model'], \\\n",
    "        lr_rate = hyper_param['learning_rate_base'], \\\n",
    "        print_trainable_layers = selected_model['print_trainable_layers'],\\\n",
    "        print_model_summary = selected_model['print_model_summary'])\n",
    "\n",
    "    # Preprocess and Augment Image for train, test and validation set. \n",
    "    transform_train, transform_val, transform_test = \\\n",
    "        pre_train.augment_images(hyper_param['image_size'])\n",
    "\n",
    "    # Prepare train, validation Generator\n",
    "    train_generator, validation_generator = pre_train.data_generator(seed = hyper_param['seed'],\\\n",
    "        transforms_train = transform_train, transforms_val = transform_val, label = label, \\\n",
    "        train_path = train_path, image_resize = image_resize,  train_batch_size = selected_model['train_batch_size'], \\\n",
    "        validation_batch_size = selected_model['validation_batch_size'])\n",
    "\n",
    "    # Visualise preprocess and augmented data\n",
    "    if selected_model['visualise_augmented_data']:\n",
    "        # Get Train set\n",
    "        train_generator.show_data()\n",
    "        # Get validation set\n",
    "        validation_generator.show_data()\n",
    "    \n",
    "    ## Define Callbacks\n",
    "    # Define Early Stopping on validation loss\n",
    "    es = EarlyStopping(monitor='val_loss', mode = 'min', patience = hyper_param['early_stop'],\\\n",
    "        verbose = 1, restore_best_weights = True)\n",
    "\n",
    "    # Save model after each epoch\n",
    "    ck = ModelCheckpoint(save_model_path + hyper_param['save_model'], monitor='val_loss', \\\n",
    "        verbose = 1, save_best_only = False, save_weights_only= False, mode='auto')\n",
    "\n",
    "    # Save logs to CSV\n",
    "    # append=False -> overwrite existing file.\n",
    "    logs = CSVLogger(log_path + selected_model['log_by'], separator=\",\", append=False)\n",
    "\n",
    "    # Callback list\n",
    "    call_backs = [warm_up_lr, ck, logs]\n",
    "\n",
    "    # Get Train and validation step size\n",
    "    STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "    start_training = input(\"Do you want to start training the model? [y]es OR [n]o: \")\n",
    "    # Start the training process is the 'yes' input is received from the terminal \n",
    "    if start_training == 'y':\n",
    "        print('\\n\\n---------------- Staring the Training Process... --------------- ')\n",
    "        # Train the model\n",
    "        history = pre_train.train_model(model = model, train_generator = train_generator, epoch = hyper_param['epoch'], \\\n",
    "            train_batch_size = hyper_param['train_batch_size'], validation_generator = validation_generator, \\\n",
    "            validation_batch_size = hyper_param['validation_batch_size'], train_step = STEP_SIZE_TRAIN, \\\n",
    "            valid_step = STEP_SIZE_VALID, callback = call_backs)\n",
    "        print(\"\\n ----------------- Model is trained --------------------------\")\n",
    "    else:\n",
    "        print(\"Training is cancelled.....\\nTerminating Python...\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Plot Training and validation loss\n",
    "    print(\"\\n------ Saving Training and Validation Plot --------\")\n",
    "    # Training and validation: accuracy & loss\n",
    "    utils.save_plot(history = history, \\\n",
    "        save_dir = plot_path + selected_model['save_plot_name'])\n",
    "\n",
    "    ############################ Predict on Testing Set\n",
    "    test_datagen = ImageDataAugmentor(\n",
    "            augment = transform_test,\n",
    "            preprocess_input = None, \n",
    "            seed = hyper_param['seed'])\n",
    "    \n",
    "    # Define test generator\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe = test_csv,\n",
    "        directory = test_path,\n",
    "        x_col = 'image',\n",
    "        target_size = image_resize,\n",
    "        class_mode = None,\n",
    "        batch_size = hyper_param['test_batch_size'],\n",
    "        shuffle = False, \n",
    "        validate_filenames = False)\n",
    "\n",
    "    # Get Test steps\n",
    "    STEP_SIZE_TEST = test_generator.n//test_generator.batch_size\n",
    "    test_generator.reset()\n",
    "\n",
    "    # predict on Testset\n",
    "    print(\"\\n------ Predicting on Testset --------\")\n",
    "    prediction = model.predict(test_generator, steps = STEP_SIZE_TEST, verbose = 1)\n",
    "    predicted_class_indices = np.argmax(prediction, axis=1)\n",
    "\n",
    "    # Map the predicted labels with their unique ids such as filenames.\n",
    "    labels = (train_generator.class_indices)\n",
    "    labels = dict((v,k) for k,v in labels.items())\n",
    "    predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "    # Save the prediction ot CSV File\n",
    "    filenames = test_generator.filenames\n",
    "    results = pd.DataFrame({\"Filename\":filenames,\n",
    "                            \"Predictions\":predictions})\n",
    "\n",
    "    prediction_path = \"./prediction/\"\n",
    "    os.makedirs(prediction_path, exist_ok = True)\n",
    "\n",
    "    results.to_csv(prediction_path + selected_model['prediction_csv_name'] + \".csv\", index=False)\n",
    "\n",
    "    ##### Save Trained Model\n",
    "    print(\"\\n ------------ Saving the Trained model ------------------------------------\")\n",
    "    final_model_path = save_model_path + '{}/'.format(hyper_param['save_final_model'])\n",
    "    os.makedirs(final_model_path, exist_ok = True)\n",
    "\n",
    "    model.save(final_model_path, save_format=\"tf\", include_optimizer = True)\n",
    "\n",
    "    print(\"\"\"\\n---------------------- Completed Model Training ---------------------------\\n\n",
    "    ------------------------- Stopping the Azure Instance ------------------------\"\"\")\n",
    "    # Stopping ComputeInstance will stop the billing meter and persist the state on the disk.\n",
    "    # Available Quota will not be changed with this operation.\n",
    "    instance.stop(wait_for_completion=True, show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d36b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\bhara\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607a1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
